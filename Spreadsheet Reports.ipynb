{
 "metadata": {
  "name": "",
  "signature": "sha256:ab519ee523f01211a2e4318601fd59ca80e10486a0303b7abb585437c863dff0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Spreadsheet Generation Report\n",
      "\n",
      "### 12th August 2014 Neil D. Lawrence\n",
      "\n",
      "This notebook contains scripts for creating spreadsheets that summarize the latest state of reviews. The script goes through the calibrated reviews (as generated by [this notebook](./Reviewer Calibration.ipynb)) and seeks papers which seem problematic in terms of either the span of the review scores, the confidence of the reviewers, the length of the reviews or those that are in the 'grey area' for publication. For each paper it creates a set of comments, which is then emailed out to area chairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cmtutils\n",
      "import pandas as pd\n",
      "import os\n",
      "date = '201"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Firstly we read in the processed reviews. The processing includes the calibrated review scores and the probability of accept. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "groups = cmtutils.pc_groupings(buddy_pair_key, '2014-08-12_conflicts.tsv', assignment_file ='2014-08-12_area_chair_assignments.xml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a report from the reviews and generate inside the structure the comments ready for depositing on spreadsheets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "report = cmtutils.review_report(filename='2014-08-12_processed_reviews.csv')\n",
      "report.spreadsheet_comments()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now load in the area chair assignments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "a = cmtutils.assignment()\n",
      "a.load_assignment(filename='2014-08-11_area_chair_assignments.xml', reviewer_type='metareviewer',)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And read in conflicts to ensure we don't show area chairs papers for which they are conflicted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read from the TSV format CMT provide.\n",
      "filename = '2014-08-11_conflicts.tsv'\n",
      "with open(os.path.join(cmtutils.nips_data_directory, filename)) as fin:\n",
      "    rows = ( line.strip().split('\\t') for line in fin)\n",
      "    conflicts_groups = { row[0]:row[1:] for row in rows}\n",
      "papers = conflicts_groups.keys()\n",
      "conflicts_by_reviewer = {}\n",
      "\n",
      "for paper in papers:\n",
      "    for reviewer in conflicts_groups[paper]:\n",
      "        if conflicts_by_reviewer.has_key(reviewer):\n",
      "            conflicts_by_reviewer[reviewer].append(paper)\n",
      "        else:\n",
      "            conflicts_by_reviewer[reviewer] = [paper]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've stored the buddy pairs in a google doc, load them in. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "buddy_pair_key = '19nxaglIIzJsPuF54matL2JVIvLrkYPrSPiwPYp_sXTE'\n",
      "bp = cmtutils.google_doc(spreadsheet_key=buddy_pair_key)\n",
      "buddy_pairs = bp.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want the area chairs first and second names for the spreadsheets. Load in the reviewer data base where these are stored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "db = cmtutils.reviewerdb('reviewers.db')\n",
      "reviewers = db.to_data_frame()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create google spreadsheets for each buddy pair, and a separate spreadsheet for the reviewer of the conflicted papers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "program_chairs = ['n.lawrence@sheffield.ac.uk', 'corinnanips@gmail.com', 'alan.saul@sheffield.ac.uk']\n",
      "spreadsheet_keys = {}\n",
      "conflict_list = {}\n",
      "num_papers = 0\n",
      "paper_list = {}\n",
      "paper_conflict = 0\n",
      "sort_order = ['prob_accept', 'attention_score']\n",
      "for pair in sorted(set(buddy_pairs.index), key=int):\n",
      "    \n",
      "    paper_list[pair] = []\n",
      "    pair_df = buddy_pairs.loc[pair]\n",
      "    for index, buddy in pair_df.iterrows():\n",
      "        conflict_papers = []\n",
      "        for chair in pair_df['area_chair']:\n",
      "            conflict_papers += conflicts_by_reviewer[chair]\n",
      "            conflict_list[chair] = []\n",
      "        for paper in a.assignment_reviewer['metareviewer'][buddy['area_chair']]:\n",
      "            if paper in conflict_papers:\n",
      "                conflict_list[chair].append(paper)\n",
      "            else:\n",
      "                paper_list[pair].append(paper)\n",
      "    num_papers+=len(paper_list[pair])\n",
      "    print index, len(paper_list[pair]), 'papers'\n",
      "    buddy_name = {}\n",
      "    for index, buddy in pair_df.iterrows():\n",
      "        email = buddy['area_chair']\n",
      "        i = reviewers.index[reviewers['Email'] == email]\n",
      "        reviewer_name  = reviewers.loc[i[0]]['FirstName'] + ' ' + reviewers.loc[i[0]]['LastName']\n",
      "        buddy_name[email] = reviewer_name\n",
      "    ds = cmtutils.google_doc(title=\"Review Summary Sheet: \" + buddy['pair'] + '---' + ', '.join(buddy_name.values()))\n",
      "    \n",
      "    comment=\"\"\"Click Me for Notes!\n",
      "    Based on processed reviews form 2014/8/12.\n",
      "    This report gives the status of the papers that don't conflict within your buddy-pair. \n",
      "    Please use it to identify papers where there may be ongoing problems. \n",
      "    Look out for papers with a high attention score and little or no discussion. \n",
      "    Your notes can be placed in the 'note' column. \n",
      "    Tentative accept/talk/spotlight decisions can be made by placing a 'y' for yes or 'm' for maybe in the relevant column.\"\"\"\n",
      "    ds.write(report.attention_report.loc[paper_list[pair]].sort(sort_order, ascending=False), comment=comment)\n",
      "    ds.share(users=buddy_name.keys() + program_chairs, send_notifications=True)\n",
      "    spreadsheet_keys[buddy['pair']] = ds.spreadsheet_key\n",
      "    comment=\"\"\"These are papers that conflict with your buddy pair, they will need to be dealt with separately. \n",
      "    Based on processed reviews form 2014/8/12.\"\"\"\n",
      "    for index, buddy in pair_df.iterrows():\n",
      "        email = buddy['area_chair']\n",
      "        personal_papers = list(set(a.assignment_reviewer['metareviewer'][email]) - set(paper_list[pair]))\n",
      "        if len(personal_papers)>0:\n",
      "            ds = cmtutils.google_doc(title=\"Review Summary Sheet: \" + buddy_name[email])\n",
      "            ds.write(report.attention_report.loc[personal_papers].sort(sort_order, ascending=False), comment=comment)\n",
      "            ds.share(users=[email] + program_chairs, send_notifications=True)\n",
      "            spreadsheet_keys[email] = ds.spreadsheet_key\n",
      "print num_papers, 'total papers without conflits'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 33 papers\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 papers\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32 papers\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 papers\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39 papers\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 papers\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35 papers\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 47 papers\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36 papers\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36 papers\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38 papers\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36 papers\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31 papers\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37 papers\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40 papers\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37 papers\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38 papers\n",
        "17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40 papers\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30 papers\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 papers\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40 papers\n",
        "21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34 papers\n",
        "22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29 papers\n",
        "23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 papers\n",
        "24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38 papers\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 papers\n",
        "26"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37 papers\n",
        "27"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 papers\n",
        "28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39 papers\n",
        "29"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 42 papers\n",
        "30"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29 papers\n",
        "31"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37 papers\n",
        "32"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 papers\n",
        "33"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35 papers\n",
        "34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28 papers\n",
        "35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30 papers\n",
        "36"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34 papers\n",
        "37"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 papers\n",
        "38"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40 papers\n",
        "39"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26 papers\n",
        "40"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37 papers\n",
        "41"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 papers\n",
        "42"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38 papers\n",
        "43"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29 papers\n",
        "44"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 papers\n",
        "1618"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " total papers\n",
        "0 total conflicts\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the spreadsheet keys (these will be vital for updating the spreadsheets with new review scores at a later date!).\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump(spreadsheet_keys, open(os.path.join(cmtutils.nips_data_directory,\"spreadsheet_keys.pickle\"), \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "load_keys = pickle.load(open(os.path.join(cmtutils.nips_data_directory, \"spreadsheet_keys.pickle\"), \"rb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    }
   ],
   "metadata": {}
  }
 ]
}